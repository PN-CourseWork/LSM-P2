#!/bin/bash
#BSUB -J scaling_3node
#BSUB -q hpcintro
#BSUB -n 72
#BSUB -R "span[ptile=24]"
#BSUB -R "rusage[mem=8GB]"
#BSUB -W 2:00
#BSUB -o logs/lsf/scaling_3node_%J.out
#BSUB -e logs/lsf/scaling_3node_%J.err

# =============================================================================
# Scaling Experiments: 3 nodes (72 cores)
# Binding: SPREAD (ppr:12:socket for even socket distribution)
# =============================================================================

module load mpi
cd $LS_SUBCWD

# Spread binding: 12 ranks per socket
MPIOPT="--map-by ppr:12:socket --bind-to core"

run_experiment() {
    local NP=$1
    local CONFIG=$2
    local EXTRA_ARGS="${@:3}"

    echo "=== Running: $CONFIG with $NP ranks ==="
    mpiexec $MPIOPT -n $NP uv run python run_solver.py \
        +experiment=$CONFIG \
        hydra/launcher=basic \
        n_ranks=$NP \
        $EXTRA_ARGS
}

# Strong Scaling: Jacobi & FMG (72 ranks)
run_experiment 72 scaling
run_experiment 72 fmg_scaling

echo "Scaling 3-node completed"
